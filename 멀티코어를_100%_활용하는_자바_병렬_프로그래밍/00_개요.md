# Chapter 0 : 개요

- [병렬 프로그래밍의 필요성](#병렬-프로그래밍의-필요성)
- [병렬성과 동시성의 차이](#병렬성과-동시성의-차이)
- [자바에서 병렬 프로그래밍을 위한 주요 도구](#자바에서-병렬-프로그래밍을-위한-주요-도구)
  - [참고) work stealing 알고리즘](#참고-work-stealing-알고리즘)
- [병렬 프로그래밍의 핵심 개념](#병렬-프로그래밍의-핵심-개념)
- [병렬 프로그래밍 시 고려할 점](#병렬-프로그래밍-시-고려할-점)
- [💡 생각해볼 점](#-생각해볼-점)

<br/>

## 병렬 프로그래밍의 필요성
- 멀티코어 프로세서의 보편화
  - `CPU 성능 향상`이 주로 `코어 수 증가`를 통해 이루어짐 -> `멀티코어를 효과적으로 활용`하는 병렬 프로그래밍이 필수적임

- 성능 향상
  - `동일한 시간` 내에 `더 많은 작업`을 처리
  - 대규모 데이터 처리와 계산 집약적 작업의 성능 개선

<br/>

## 병렬성과 동시성의 차이
- `동시성(Concurrency)` : 여러 작업이 `동시에 실행되는 것처럼 보이는` 것
  - CPU가 빠르게 작업을 전환(Switching)하여 실행
  - 단일 코어에서도 동시성 구현 가능
  - ex) 하나의 코어에서 멀티태스킹 처리

- `병렬성(Parallelism)` : 여러 작업이 `진짜로 동시에 실행`되는 것
  - 멀티코어에서 각 코어가 별도의 작업을 처리
  - ex) 데이터 병렬 처리, 대규모 연산 분산 처리
 
<br/>

- CPU와 코어의 관계    
  - 🏛️ CPU = 건물
  - 🏢 코어 = 건물 안의 독립적인 사무실

<br/><br/>

## 자바에서 병렬 프로그래밍을 위한 주요 도구
- `java.lang.Thread` : thread를 `수동으로` 생성하고 관리 -> 복잡하고 오류 발생 가능성 높음

- `ExecutorService` : `thread pool`을 통해 thread 생성 및 관리를 추상화
  - FixedThreadPool, CachedThreadPool 등 다양한 pool 제공

- `ForkJoinPool` : 분할 정복(Divide and Conquer) 전략을 사용하여 큰 작업을 작은 작업으로 `재귀적으로 분할(fork)`하고 다시 `결과를 합치는(join)` 병렬 처리하기 위한 thread pool
  - CPU 바운드 작업에 적합
  - 주로 ForkJoinTask를 사용하여 병렬 실행을 지원
  - Java 7부터 제공
  - ForkJoinPool은 work stealing 알고리즘을 사용     

- `parallelStream()` : Java 8부터 제공되는 `Stream의 병렬 처리` 기능
  - 내부적으로 ForkJoinPool 사용
 
<br/>

### 참고) work stealing 알고리즘   
놀고 있는 thread가 다른 thread의 작업을 훔쳐와 처리하는 전략    
`thread 간 작업량을 자동으로 분산`하여 불필요한 thread 전환을 줄이고 CPU 코어가 놀지 않도록 보장


**동작 방식**   
1. 작업 분할 (Fork) : 큰 작업을 여러 작은 작업으로 분할    
각 thread는 자기 작업 큐(deque)에 작업을 추가함

2. 작업 처리 : 각 thread는 `자신의 큐에서 작업을 처리`   
큐의 가장 `마지막 작업부터 처리(LIFO 방식)`하여 캐시 효율성을 높임    

3. 작업 훔치기 (Work Stealing)    
어떤 thread의 작업이 끝나면, `다른 thread의 queue 앞부분에서` 작업을 훔쳐오기(FIFO 방식)     
➡️ 모든 thread가 바쁘게 일하도록 유지 -> CPU 자원의 효율성 극대화

<br/><br/>

## 병렬 프로그래밍의 핵심 개념
- 작업 분할(Decomposition): 큰 작업을 `작은 단위로` 나누어 각 코어에 분배

- 작업 병합(Composition): 각 코어에서 처리된 `결과를 하나로` 병합

- 스레드 안전(Thread Safety): 병렬 처리 중 데이터 경쟁(Race Condition)을 피하기 위한 `동기화` 필요

- 부하 분산(Load Balancing): 각 코어가 비슷한 양의 작업을 수행하도록 작업을 `균등하게 분배`

<br/><br/>

## 병렬 프로그래밍 시 고려할 점

💥 core 수보다 `많은 thread`가 생성되면?     
CPU는 여러 thread를 같은 core에서 전환(Context Switching) 해야함    

=> 이때 다음과 같은 오버헤드가 발생    
- `context switching 비용` : thread를 전환할 때 CPU는 현재 실행 중인 thread의 상태(register, memory 등)를 저장하고, 새로운 thread의 상태를 복원해야 함 -> 시간이 걸리며 성능 저하의 원인    

- `thread 생성 및 소멸 비용` : thread를 너무 많이 생성하면 생성과 소멸 과정에서도 리소스 낭비 발생

- `동기화 비용 (Synchronization Overhead)` : 여러 thread가 동일한 자원 (ex) 공유 메모리) 을 접근할 때 lock을 사용하게 되면 대기 시간이 발생할 수 있음

<br/>

=> 고려 필요 사항   
- 오버헤드 관리: 스레드 생성, 컨텍스트 스위칭 등에서 발생하는 오버헤드를 최소화

- 데이터 동기화: 공유 자원의 동기화로 인한 성능 저하 방지

- 적절한 알고리즘 선택: 병렬 처리에 적합한 알고리즘 사용 (ex) 맵리듀스, 분할 정복)

- CPU 캐시 활용: 메모리 접근 지연을 줄이기 위한 캐시 친화적 프로그래밍

<br/><br/>

## 💡 생각해볼 점
- 멀티코어 활용은 `성능 향상과 응답성 개선`의 핵심  
  병렬성과 동시성의 차이를 이해하고, 상황에 맞는 적절한 전략을 선택해야함     
  ExecutorService, ForkJoinPool, parallelStream() 등의 자바 병렬 처리 도구 활용하자   
  이 때, `thread 안전성`과 `오버헤드 관리`가 병렬 프로그래밍 성능 최적화의 핵심이다     

<br/>

- 병렬 프로그래밍은 이론적으로 작업을 나누어 빠르게 처리할 수 있지만, `과도한 thread 생성이나 잦은 thread 전환`은 오히려 `성능을 저하`시킬 수 있음    

  - 예를 들어, 4개의 코어가 있는데 100개의 thread를 생성한다면 각 코어가 번갈아 thread를 실행해야 해서 context switching 비용이 커지고, 실제 작업 처리 시간은 줄어들어 병렬성의 장점을 잃게 됨

  - 💡 실제로 사내 코드에서 구현할 때 CachedThreadPool에서 FixedThreadPool 로 변경하여 사용하였을 때 작업 시간이 더 빨라진 경우가 있었음

<br/>

- 병렬프로그램의 오버헤드 관리는 어떻게 하면 좋을까  

  ✅ `thread pool 사용 (ExecutorService)`        
  매번 새로운 thread를 생성하는 대신, 재사용할 수 있는 thread pool을 사용해 오버헤드를 줄이기       
  - ex) Executors.newFixedThreadPool(4)로 코어 수에 맞게 thread 수 제한

  <br/>

  ✅ `작업의 적절한 분할`   
  너무 작은 작업으로 나누면 작업 분할과 병합하는 데 드는 비용이 커짐    
  적절한 크기로 작업을 분할해 병렬화의 이점을 유지해야함    

  <br/>

  ✅ `ForkJoinPool 사용`   
  work stealing 알고리즘을 사용하여 불필요한 thread 전환을 줄이고 CPU 코어가 놀지 않도록 보장해줌      

<br/>

- ForkJoinPool 예제

  ```java
  import java.util.concurrent.*;

  public class ForkJoinExample extends RecursiveTask<Long> {
      private final long start, end;
      private static final long THRESHOLD = 10_000L;
  
      public ForkJoinExample(long start, long end) {
          this.start = start;
          this.end = end;
      }
  
      @Override
      protected Long compute() {
          if ((end - start) <= THRESHOLD) {
              long sum = 0;
              for (long i = start; i <= end; i++) sum += i;
              return sum;
          } else {
              long mid = (start + end) / 2;
              ForkJoinExample left = new ForkJoinExample(start, mid);
              ForkJoinExample right = new ForkJoinExample(mid + 1, end);
  
              left.fork();  // 새로운 thread에서 작업을 병렬로 처리하도록 시작
              return right.compute() + left.join();  // main thread는 left 작업 끝날 때까지 기다렸다가 결과 합치기
              // 만약 left 작업이 먼저 끝난다면 이는 여유 있는 thread가 되어 right의 남은 작업을 훔쳐서 처리할 수도 있음 :: ForkJoinPool이 여유 있는 thread를 이용해 작업을 분배함
          }
      }
  
      public static void main(String[] args) {
          ForkJoinPool pool = new ForkJoinPool();  // ForkJoinPool은 각 thread가 자신만의 작업 큐를 가짐
          ForkJoinExample task = new ForkJoinExample(1, 1_000_000L);  // 큰 작업
          long result = pool.invoke(task);  // 작업을 분할 & 병합해서 처리
          System.out.println("결과: " + result);
      }
  }
  ```

  - `ForkJoinPool` 과 `다른 일반적인 thread pool(ExecutorService 계열)` 의 `작업 큐 처리 방식` 차이    

    - 일반적인 thread pool (ex) ExecutorService)
      - `단일 큐` 사용 : 하나의 큐에서 모든 thread가 작업을 가져감
      - thread가 대기 중인 큐에서 작업을 가져가서 실행하며, thread가 작업을 수행 중일 때 다른 thread들이 대기 큐에서 작업을 가져옴

    - ForkJoinPool
      - `자신만의 작업 큐` : ForkJoinPool은 각 thread가 자신만의 작업 큐를 가짐 이를 통해 작업을 훔쳐서 처리하는(Work Stealing) 방식을 구현      
      - thread 간에 작업을 효율적으로 분배하는 방식으로 성능을 최적화   
     
      => 💡 CachedThreadPool에서 FixedThreadPool 로 변경한 부분에서 ExecutorService 로 구현하였는데 ForkJoinPool 사용도 테스트해보아야겠다   

<br/>
